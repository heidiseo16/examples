{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01131cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install scrapbook recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6867f551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import scrapbook as sb\n",
    "import pandas as pd\n",
    "import sklearn.preprocessing\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR') # only show error messages\n",
    "\n",
    "from recommenders.utils.constants import (\n",
    "    SEED,\n",
    "    DEFAULT_PREDICTION_COL as PREDICT_COL\n",
    ")\n",
    "from recommenders.datasets.python_splitters import python_random_split\n",
    "from recommenders.datasets.pandas_df_utils import user_item_pairs\n",
    "from recommenders.utils import tf_utils, gpu_utils, plot\n",
    "import recommenders.evaluation.python_evaluation as evaluator\n",
    "import recommenders.models.wide_deep.wide_deep_utils as wide_deep\n",
    "\n",
    "print(\"Tensorflow Version:\", tf.__version__)\n",
    "print(\"GPUs:\\n\", gpu_utils.get_gpu_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5149e548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input, output path\n",
    "INPUT_PATH = '/input'\n",
    "OUTPUT_PATH = '/output'\n",
    "\n",
    "# Columns\n",
    "USER_COL = 'userId'\n",
    "ITEM_COL = 'movieId'\n",
    "RATING_COL = 'rating'\n",
    "ITEM_FEAT_COL = 'genres'\n",
    "\n",
    "# Recommend top k items\n",
    "TOP_K = 10\n",
    "\n",
    "# Metrics to use for evaluation\n",
    "RANKING_METRICS = [\n",
    "    evaluator.ndcg_at_k.__name__,\n",
    "    evaluator.precision_at_k.__name__,\n",
    "]\n",
    "RATING_METRICS = [\n",
    "    evaluator.rmse.__name__,\n",
    "    evaluator.mae.__name__,\n",
    "]\n",
    "\n",
    "# Set seed for deterministic result\n",
    "RANDOM_SEED = SEED\n",
    "\n",
    "# Use session hook to evaluate model while training\n",
    "EVALUATE_WHILE_TRAINING = True\n",
    "\n",
    "#### Hyperparameters\n",
    "MODEL_TYPE = 'wide_deep'\n",
    "STEPS = 50000  # Number of batches to train\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Wide (linear) model hyperparameters\n",
    "LINEAR_OPTIMIZER = 'adagrad'\n",
    "LINEAR_OPTIMIZER_LR = 0.0621  # Learning rate\n",
    "LINEAR_L1_REG = 0.0           # Regularization rate for FtrlOptimizer\n",
    "LINEAR_L2_REG = 0.0\n",
    "LINEAR_MOMENTUM = 0.0         # Momentum for MomentumOptimizer or RMSPropOptimizer\n",
    "\n",
    "# DNN model hyperparameters\n",
    "DNN_OPTIMIZER = 'adadelta'\n",
    "DNN_OPTIMIZER_LR = 0.1\n",
    "DNN_L1_REG = 0.0           # Regularization rate for FtrlOptimizer\n",
    "DNN_L2_REG = 0.0\n",
    "DNN_MOMENTUM = 0.0         # Momentum for MomentumOptimizer or RMSPropOptimizer\n",
    "\n",
    "# Layer dimensions. Defined as follows to make this notebook runnable from Hyperparameter tuning services like AzureML Hyperdrive\n",
    "DNN_HIDDEN_LAYER_1 = 0     # Set 0 to not use this layer\n",
    "DNN_HIDDEN_LAYER_2 = 64    # Set 0 to not use this layer\n",
    "DNN_HIDDEN_LAYER_3 = 128   # Set 0 to not use this layer\n",
    "DNN_HIDDEN_LAYER_4 = 512   # Note, at least one layer should have nodes.\n",
    "DNN_HIDDEN_UNITS = [h for h in [DNN_HIDDEN_LAYER_1, DNN_HIDDEN_LAYER_2, DNN_HIDDEN_LAYER_3, DNN_HIDDEN_LAYER_4] if h > 0]\n",
    "DNN_USER_DIM = 32          # User embedding feature dimension\n",
    "DNN_ITEM_DIM = 16          # Item embedding feature dimension\n",
    "DNN_DROPOUT = 0.8\n",
    "DNN_BATCH_NORM = 1         # 1 to use batch normalization, 0 if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f340a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir, filename):\n",
    "    data_path = os.path.join(data_dir, filename)\n",
    "    raw_data = pd.read_csv(data_path)\n",
    "    return raw_data\n",
    "\n",
    "data = load_data(INPUT_PATH, \"ratings.csv\")\n",
    "movies = load_data(INPUT_PATH, \"movies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909e1df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9390c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess dataset\n",
    "new_data = data.set_index(ITEM_COL).join(movies.set_index(ITEM_COL)).filter([USER_COL, ITEM_COL, RATING_COL, ITEM_FEAT_COL]).reset_index()\n",
    "genres_encoder = sklearn.preprocessing.MultiLabelBinarizer()\n",
    "new_data[ITEM_FEAT_COL] = genres_encoder.fit_transform(\n",
    "    new_data[ITEM_FEAT_COL].apply(lambda s: s.split(\"|\"))\n",
    ").tolist()\n",
    "train, test = python_random_split(new_data, ratio=0.75, seed=RANDOM_SEED)\n",
    "train.shape[0], test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a14aaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique items in the dataset\n",
    "items = new_data.drop_duplicates(ITEM_COL)[[ITEM_COL, ITEM_FEAT_COL]].reset_index(drop=True)\n",
    "item_feat_shape = len(items[ITEM_FEAT_COL][0])\n",
    "# Unique users in the dataset\n",
    "users = new_data.drop_duplicates(USER_COL)[[USER_COL]].reset_index(drop=True)\n",
    "\n",
    "print(\"Total {} items and {} users in the dataset\".format(len(items), len(users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e51acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define wide (linear) and deep (dnn) features\n",
    "wide_columns, deep_columns = wide_deep.build_feature_columns(\n",
    "    users=users[USER_COL].values,\n",
    "    items=items[ITEM_COL].values,\n",
    "    user_col=USER_COL,\n",
    "    item_col=ITEM_COL,\n",
    "    item_feat_col=ITEM_FEAT_COL,\n",
    "    crossed_feat_dim=1000,\n",
    "    user_dim=DNN_USER_DIM,\n",
    "    item_dim=DNN_ITEM_DIM,\n",
    "    item_feat_shape=item_feat_shape,\n",
    "    model_type=MODEL_TYPE,\n",
    ")\n",
    "\n",
    "print(\"Wide feature specs:\")\n",
    "for c in wide_columns:\n",
    "    print(\"\\t\", str(c)[:100], \"...\")\n",
    "print(\"Deep feature specs:\")\n",
    "for c in deep_columns:\n",
    "    print(\"\\t\", str(c)[:100], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a982571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model checkpoint every n steps. We store the model 5 times.\n",
    "save_checkpoints_steps = max(1, STEPS // 5)\n",
    "\n",
    "# Build a model based on the parameters\n",
    "model_dir = OUTPUT_PATH\n",
    "model = wide_deep.build_model(\n",
    "    model_dir=model_dir,\n",
    "    wide_columns=wide_columns,\n",
    "    deep_columns=deep_columns,\n",
    "    linear_optimizer=tf_utils.build_optimizer(LINEAR_OPTIMIZER, LINEAR_OPTIMIZER_LR, **{\n",
    "        'l1_regularization_strength': LINEAR_L1_REG,\n",
    "        'l2_regularization_strength': LINEAR_L2_REG,\n",
    "        'momentum': LINEAR_MOMENTUM,\n",
    "    }),\n",
    "    dnn_optimizer=tf_utils.build_optimizer(DNN_OPTIMIZER, DNN_OPTIMIZER_LR, **{\n",
    "        'l1_regularization_strength': DNN_L1_REG,\n",
    "        'l2_regularization_strength': DNN_L2_REG,\n",
    "        'momentum': DNN_MOMENTUM,  \n",
    "    }),\n",
    "    dnn_hidden_units=DNN_HIDDEN_UNITS,\n",
    "    dnn_dropout=DNN_DROPOUT,\n",
    "    dnn_batch_norm=(DNN_BATCH_NORM==1),\n",
    "    log_every_n_iter=max(1, STEPS//10),  # log 10 times\n",
    "    save_checkpoints_steps=save_checkpoints_steps,\n",
    "    seed=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c486c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare ranking evaluation set, i.e. get the cross join of all user-item pairs\n",
    "ranking_pool = user_item_pairs(\n",
    "    user_df=users,\n",
    "    item_df=items,\n",
    "    user_col=USER_COL,\n",
    "    item_col=ITEM_COL,\n",
    "    user_item_filter_df=train,  # Remove seen items\n",
    "    shuffle=True,\n",
    "    seed=RANDOM_SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4099919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training hooks to track performance while training\n",
    "hooks = []\n",
    "cols = {\n",
    "    'col_user': USER_COL,\n",
    "    'col_item': ITEM_COL,\n",
    "    'col_rating': RATING_COL,\n",
    "    'col_prediction': PREDICT_COL,\n",
    "}\n",
    "if EVALUATE_WHILE_TRAINING:\n",
    "    evaluation_logger = tf_utils.MetricsLogger()\n",
    "    for metrics in (RANKING_METRICS, RATING_METRICS):\n",
    "        if len(metrics) > 0:\n",
    "            hooks.append(\n",
    "                tf_utils.evaluation_log_hook(\n",
    "                    model,\n",
    "                    logger=evaluation_logger,\n",
    "                    true_df=test,\n",
    "                    y_col=RATING_COL,\n",
    "                    eval_df=ranking_pool if metrics==RANKING_METRICS else test.drop(RATING_COL, axis=1),\n",
    "                    every_n_iter=save_checkpoints_steps,\n",
    "                    model_dir=model_dir,\n",
    "                    eval_fns=[evaluator.metrics[m] for m in metrics],\n",
    "                    **({**cols, 'k': TOP_K} if metrics==RANKING_METRICS else cols)\n",
    "                )\n",
    "            )\n",
    "\n",
    "# Define training input (sample feeding) function\n",
    "train_fn = tf_utils.pandas_input_fn(\n",
    "    df=train,\n",
    "    y_col=RATING_COL,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_epochs=None,  # We use steps=TRAIN_STEPS instead.\n",
    "    shuffle=True,\n",
    "    seed=RANDOM_SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4958aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    \"Training steps = {}, Batch size = {} (num epochs = {})\"\n",
    "    .format(STEPS, BATCH_SIZE, (STEPS*BATCH_SIZE)//len(train))\n",
    ")\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.INFO)\n",
    "\n",
    "try:\n",
    "    model.train(\n",
    "        input_fn=train_fn,\n",
    "        hooks=hooks,\n",
    "        steps=STEPS\n",
    "    )\n",
    "except tf.train.NanLossDuringTrainingError:\n",
    "    import warnings\n",
    "    warnings.warn(\n",
    "        \"Training stopped with NanLossDuringTrainingError. \"\n",
    "        \"Try other optimizers, smaller batch size and/or smaller learning rate.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c9f703",
   "metadata": {},
   "outputs": [],
   "source": [
    "if EVALUATE_WHILE_TRAINING:\n",
    "    logs = evaluation_logger.get_log()\n",
    "    for i, (m, v) in enumerate(logs.items(), 1):\n",
    "        sb.glue(\"eval_{}\".format(m), v)\n",
    "        x = [save_checkpoints_steps*i for i in range(1, len(v)+1)]\n",
    "        plot.line_graph(\n",
    "            values=list(zip(v, x)),\n",
    "            labels=m,\n",
    "            x_name=\"steps\",\n",
    "            y_name=m,\n",
    "            subplot=(math.ceil(len(logs)/2), 2, i),\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Full on Python 3.6 (GPU)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
